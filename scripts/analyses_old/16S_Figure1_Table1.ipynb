{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/AHN/captive_ape_microbiome/results/16s'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ete3 import Tree\n",
    "from collections import Counter\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Volumes/AHN/captive_ape_microbiome/results/16s/')\n",
    "metadata_file = 'inputs_old/16S_metadata.txt'\n",
    "tax_table_file = 'inputs_old/ASVs_taxonomy.txt'\n",
    "asv_table_file = 'inputs_old/ASV_tab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### designate 16-ASVs as host-restricted, mixed host, or unique to captive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in asv table, get sample names and number for each asv\n",
    "def is_HR(sampleNames,sample_type_dict):\n",
    "    \"\"\"given a list of sample names uses sample type dictionary to determine how many sample types are present\n",
    "    designates ASVs as host restricted = 1 sample type or mixed = multiple sample types.\n",
    "    Captive sample types are not considered so some clades will have a 0 sample type length and they can fall within\n",
    "    host-restricted clades or mixed clades or neither\"\"\"\n",
    "    sampleTypes = [sample_type_dict[name] for name in sampleNames]\n",
    "    sampleTypes = [x.replace('non_western_','').replace('western_','') for x in sampleTypes]\n",
    "    neutral_sampleTypes = ['captive_gorilla','captive_bonobo','captive_chimp','captive_orangutan']\n",
    "    captiveNames = [name for name in sampleNames if 'captive' in sample_type_dict[name]]\n",
    "    HR_sampleTypes = list(set(sampleTypes) - set(neutral_sampleTypes))\n",
    "    HR_sampleNum = len([x for x in sampleTypes if x not in neutral_sampleTypes])\n",
    "    CP_sampleTypes = list(set(sampleTypes) & set(neutral_sampleTypes))\n",
    "    CP_sampleNum = len([x for x in sampleTypes if x in neutral_sampleTypes])\n",
    "    CP_pres = True if len(CP_sampleTypes) > 0 else False\n",
    "    if len(HR_sampleTypes) == 0:\n",
    "        HR_cat,HR_type='Unique_CP','Unique_CP'\n",
    "    if len(HR_sampleTypes) == 1: #identifies host-restricted clades\n",
    "        HR_cat,HR_type='HR','HR_'+HR_sampleTypes[0]  \n",
    "    if len(HR_sampleTypes) > 1: \n",
    "        HR_cat = 'MX'\n",
    "        if len(HR_sampleTypes) == 2:\n",
    "            if 'human' in HR_sampleTypes:\n",
    "                HR_type = 'MX_human_single_wild_ape'\n",
    "            else:\n",
    "                HR_type = 'MX_2_wild_apes'\n",
    "        if len(HR_sampleTypes) == 3:\n",
    "            if 'human' in HR_sampleTypes:\n",
    "                HR_type = 'MX_human_2_wild_apes'\n",
    "            else:\n",
    "                HR_type = 'MX_3_wild_apes'\n",
    "        if len(HR_sampleTypes) == 4:\n",
    "            HR_type = 'MX_4_hominids'\n",
    "        \n",
    "    return(HR_sampleTypes,HR_sampleNum,HR_cat,HR_type,CP_pres,CP_sampleNum,CP_sampleTypes,captiveNames)\n",
    "\n",
    "\n",
    "def asv_hr_table(asv_table_file,metadata_file,tax_table_file):\n",
    "    asv_table = pd.read_csv(asv_table_file,sep='\\t',index_col=0)\n",
    "    sampleNames = asv_table.apply(lambda row: list(row.index[row>0]),axis=1)\n",
    "    asv_df = sampleNames.reset_index()\n",
    "    asv_df.columns = ['ASV','sampleNames']\n",
    "    asv_df['sampleNum'] = asv_df['sampleNames'].apply(lambda names: len(names))\n",
    "    \n",
    "    #add host restriction info\n",
    "    metadata = pd.read_csv(metadata_file,sep='\\t',index_col=None)\n",
    "    sample_type_dict = dict(zip(metadata['X.SampleID'], metadata['Description'])) \n",
    "    hr = asv_df['sampleNames'].apply(lambda x: pd.Series(is_HR(x,sample_type_dict),\n",
    "                                                         index=['HR_sampleTypes','HR_sampleNum','HR_cat','HR_type',\n",
    "                                                                'CP_pres','CP_sampleNum','CP_sampleTypes','captiveNames']))\n",
    "    asv_hr_df = asv_df.merge(hr,left_index=True, right_index=True)\n",
    "    \n",
    "    #add taxonomic info\n",
    "    tax_table = pd.read_csv(tax_table_file,sep='\\t',index_col=None)\n",
    "    tax_table = tax_table[['ASV','Phylum','Order','Family','Genus']]\n",
    "    asv_full = asv_hr_df.merge(tax_table,on='ASV',how='left')\n",
    "    \n",
    "    return(asv_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977 total 16S ASVs\n",
      "871 16S ASVs found in captive apes\n",
      "HR_human                    227\n",
      "MX_human_single_wild_ape    187\n",
      "MX_4_hominids               166\n",
      "MX_human_2_wild_apes        128\n",
      "Unique_CP                   106\n",
      "MX_2_wild_apes               20\n",
      "MX_3_wild_apes               19\n",
      "HR_wild_chimp                10\n",
      "HR_wild_gorilla               8\n",
      "Name: HR_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "asv_16s = asv_hr_table(asv_table_file,metadata_file,tax_table_file)\n",
    "print(len(asv_16s),'total 16S ASVs')\n",
    "asv_16s_captive = asv_16s[asv_16s['CP_pres']==True]\n",
    "print(len(asv_16s_captive),'16S ASVs found in captive apes')\n",
    "#print(asv_16s_captive.head())\n",
    "print(asv_16s_captive['HR_type'].value_counts())\n",
    "asv_16s.to_csv('analyses/tables/16S_ASVs_summary_old.txt',sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ASV</th>\n",
       "      <th>sampleNames</th>\n",
       "      <th>sampleNum</th>\n",
       "      <th>HR_sampleTypes</th>\n",
       "      <th>HR_sampleNum</th>\n",
       "      <th>HR_cat</th>\n",
       "      <th>HR_type</th>\n",
       "      <th>CP_pres</th>\n",
       "      <th>CP_sampleNum</th>\n",
       "      <th>CP_sampleTypes</th>\n",
       "      <th>captiveNames</th>\n",
       "      <th>Phylum</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, ASV, sampleNames, sampleNum, HR_sampleTypes, HR_sampleNum, HR_cat, HR_type, CP_pres, CP_sampleNum, CP_sampleTypes, captiveNames, Phylum, Order, Family, Genus]\n",
       "Index: []"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#asv_16s_old = pd.read_csv('analyses/tables/16S_ASVs_summary_old.txt',sep='\\t').sort_values('ASV').reset_index()\n",
    "#asv_16s = pd.read_csv('analyses/tables/16S_ASVs_summary.txt',sep='\\t').sort_values('ASV').reset_index()\n",
    "#asv_16s[asv_16s['ASV']!=asv_16s_old['ASV']]\n",
    "#asv_16s[asv_16s['sampleNames']!=asv_16s_old['sampleNames']]\n",
    "#asv_16s[asv_16s['CP_pres']!=asv_16s_old['CP_pres']]\n",
    "#asv_16s_old[asv_16s['CP_pres']!=asv_16s_old['CP_pres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine distribution of captive associated 16-ASVs across host species and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_site_sp(cp_desc):\n",
    "    \"\"\"Designate ASVs based on whether they are found across \n",
    "    multiple locations or a single location, observed in a single\n",
    "    host species or multiple host species\"\"\"\n",
    "    sites = list(set([x.split('_')[0] for x in cp_desc]))\n",
    "    sitesNum = len(sites)\n",
    "    sitesMulti = 'multi_site' if sitesNum > 1 else 'single_site'      \n",
    "    species = list(set([x.split('_')[2] for x in cp_desc]))\n",
    "    speciesNum = len(species)\n",
    "    speciessMulti = 'multi_sp' if speciesNum > 1 else 'single_sp' \n",
    "    return(sitesMulti + '_' + speciessMulti)\n",
    "\n",
    "#multi_site_sp(['HOUZ_captive_chimp','HOUZ_captive_gorilla'])\n",
    "\n",
    "def captive_apes_asv_summary(asv_hr_table_output,metadata_file):\n",
    "    asv_cp = asv_hr_table_output[asv_hr_table_output['CP_pres']==True]\n",
    "    metadata = pd.read_csv(metadata_file,sep='\\t',index_col=None)\n",
    "    metadata['Description_site'] = metadata['site_code']+'_'+metadata['Description']\n",
    "    sample_type_site_dict = dict(zip(metadata['X.SampleID'], metadata['Description_site']))\n",
    "\n",
    "    description_df = asv_cp['sampleNames'].apply(lambda l: pd.Series(\n",
    "        [sample_type_site_dict[name] for name in l]).value_counts())\n",
    "    description_df = description_df.fillna(0)  \n",
    "    capt_desc = list(set(metadata['Description_site'][metadata['captivity_status']=='captive']))\n",
    "    description_df = description_df[capt_desc]\n",
    "    description_df['CP_sp_loc'] = description_df.apply(lambda row: list(row.index[row>0]),axis=1)\n",
    "    description_df['numEnclosure'] = description_df['CP_sp_loc'].apply(lambda x: len(x))\n",
    "    description_df['multi_site_sp'] = description_df['CP_sp_loc'].apply(lambda x:  \n",
    "                                                                        multi_site_sp(x))\n",
    "    asv_cp_table = asv_cp.merge(description_df,left_index=True,right_index=True)\n",
    "    return(asv_cp_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'['",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-e09519b00c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masv_cp_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaptive_apes_asv_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masv_16s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetadata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0masv_cp_table_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masv_cp_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_site_sp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masv_cp_table_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#asv_cp_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0masv_cp_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'analyses/figures/16S_captive_Figure1A_data.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5afa9d0f4795>\u001b[0m in \u001b[0;36mcaptive_apes_asv_summary\u001b[0;34m(asv_hr_table_output, metadata_file)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0msample_type_site_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X.SampleID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description_site'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     description_df = asv_cp['sampleNames'].apply(lambda l: pd.Series(\n\u001b[0m\u001b[1;32m     22\u001b[0m         [sample_type_site_dict[name] for name in l]).value_counts())\n\u001b[1;32m     23\u001b[0m     \u001b[0mdescription_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ete/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5afa9d0f4795>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     description_df = asv_cp['sampleNames'].apply(lambda l: pd.Series(\n\u001b[0;32m---> 22\u001b[0;31m         [sample_type_site_dict[name] for name in l]).value_counts())\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdescription_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcapt_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description_site'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'captivity_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'captive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5afa9d0f4795>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     description_df = asv_cp['sampleNames'].apply(lambda l: pd.Series(\n\u001b[0;32m---> 22\u001b[0;31m         [sample_type_site_dict[name] for name in l]).value_counts())\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdescription_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcapt_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description_site'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'captivity_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'captive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '['"
     ]
    }
   ],
   "source": [
    "asv_cp_table = captive_apes_asv_summary(asv_16s,metadata_file)\n",
    "asv_cp_table_summary = asv_cp_table.groupby(['multi_site_sp']).size().reset_index(name=\"count\")\n",
    "print(asv_cp_table_summary)\n",
    "#asv_cp_table\n",
    "asv_cp_table.to_csv('analyses/figures/16S_captive_Figure1A_data.txt',sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine proportion of shared ASVs (Figure 1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def add_tax_to_asv_table(asv_table_file,tax_table_file):\n",
    "    \"\"\"adds taxonomic information to the last few columns of the ASV table\"\"\"\n",
    "    asv_table = pd.read_csv(asv_table_file,sep='\\t',index_col=0)\n",
    "    asv_table = asv_table.reset_index().rename(columns={\"index\": \"ASV\"})\n",
    "    tax_table = pd.read_csv(tax_table_file,sep='\\t',index_col=None)\n",
    "    asv_table_tax = asv_table.merge(tax_table[['ASV','Phylum','Order','Family','Genus']],on='ASV',how='left')\n",
    "    asv_table_tax = asv_table_tax[asv_table_tax['Genus']!='Unassigned']\n",
    "    asv_table_tax = asv_table_tax[~asv_table_tax['Genus'].isna()]\n",
    "    return(asv_table_tax)\n",
    "\n",
    "def get_sp_site_comp(ind1,ind2):\n",
    "    \"\"\"determines if any two samples belongs to the same host species or location\"\"\"\n",
    "    sp = ('same_spec' if ind1.split('_')[2] == ind2.split('_')[2] else 'diff_spec')\n",
    "    st = ('same_site' if ind1.split('_')[0] == ind2.split('_')[0] else 'diff_site')\n",
    "    return(sp+'_'+st)\n",
    "get_sp_site_comp('COLZ_captive_bonobo','COLZ_captive_chimp')\n",
    "\n",
    "\n",
    "def pw_metadata_capt_samples(metadata_file):\n",
    "    \"\"\"generate all pairwise comparisons between two individuals with host species and site metadata\"\"\"\n",
    "    metadata = pd.read_csv(metadata_file,sep='\\t',index_col=None)\n",
    "    metadata['Description_site'] = metadata['site_code']+'_'+metadata['Description']\n",
    "    sample_type_site_dict = dict(zip(metadata['X.SampleID'], metadata['Description_site']))\n",
    "\n",
    "    cp_samples = metadata['X.SampleID'][metadata['captivity_status']=='captive']\n",
    "    pw_df = pd.DataFrame(combinations(cp_samples, 2),columns=['ind1','ind2'])\n",
    "    pw_df['desc_site_ind1'] = pw_df['ind1'].apply(lambda x:sample_type_site_dict[x])\n",
    "    pw_df['desc_site_ind2'] = pw_df['ind2'].apply(lambda x:sample_type_site_dict[x])\n",
    "    pw_df['full_desc_comp'] = pw_df['desc_site_ind1'] + '_vs_' + pw_df['desc_site_ind2']\n",
    "    pw_df['sp_site_comp'] = pw_df.apply(lambda row: \n",
    "                                        get_sp_site_comp(row['desc_site_ind1'],row['desc_site_ind2']),\n",
    "                                        axis=1)\n",
    "    return(pw_df)\n",
    "\n",
    "\n",
    "def shared_ASVs_common_gen(ind1,ind2,asv_table_gen):\n",
    "    pw = asv_table_gen[['Phylum','Order','Family','Genus','ASV',ind1,ind2]][\n",
    "        (asv_table_gen[ind1]>0)|(asv_table_gen[ind2]>0)\n",
    "        ]\n",
    "    #print(pw)\n",
    "    common_gen = list(\n",
    "                 set(pw[pw[ind1]>0]['Genus']) & \n",
    "                 set(pw[pw[ind2]>0]['Genus']))\n",
    "    len_common_gen = len(common_gen)\n",
    "    \n",
    "    pw= pw[pw['Genus'].isin(common_gen)]\n",
    "    ind1_ASVs = len(pw[(pw[ind1]>0)])\n",
    "    ind2_ASVs = len(pw[(pw[ind2]>0)])\n",
    "    common_ASVs = len(pw[(pw[ind1]>0)&(pw[ind2]>0)]) \n",
    "    if len_common_gen > 0:\n",
    "        prop_shared = common_ASVs/min(ind1_ASVs,ind2_ASVs)\n",
    "    else:\n",
    "        prop_shared = 'nan'\n",
    "    res = pd.Series([ind1,ind2,common_gen,len_common_gen,ind1_ASVs,ind2_ASVs,common_ASVs,prop_shared],\n",
    "              index=['ind1','ind2','common_gen','len_common_gen',\n",
    "                     'ind1_ASVs','ind2_ASVs','common_ASVs','prop_shared'])\n",
    "    return(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_df = pw_metadata_capt_samples(metadata_file)\n",
    "asv_table_tax = add_tax_to_asv_table(asv_table_file,tax_table_file)\n",
    "shared_ASV_all_genera = pw_df.apply(lambda row: \n",
    "                    shared_ASVs_common_gen(row['ind1'],row['ind2'],asv_table_tax),axis=1)\n",
    "pw_shared_ASV_all_genera = pw_df.merge(shared_ASV_all_genera,on=['ind1','ind2'])                       \n",
    "pw_shared_ASV_all_genera.to_csv(\n",
    "    'analyses/figures/16S_captive_Figure1B_data.txt',\n",
    "    sep='\\t',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"diff_spec_diff_site mean\" \"0.615436040485297\"       \n",
      "[1] \"diff_spec_same_site mean\" \"0.645869535219191\"       \n",
      "[1] \"same_spec_diff_site\" \"0.626528995471842\"  \n",
      "[1] \"same_spec_same_site\" \"0.753325130301663\"  \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(ggplot2)\n",
    "table_file <- paste0('analyses/figures/16S_captive_Figure1B_data.txt')\n",
    "Figure1B_data = read.table(table_file,header=TRUE,sep='\\t')\n",
    "\n",
    "Figure1B <- ggplot(Figure1B_data, aes(x=sp_site_comp, y=prop_shared,fill=sp_site_comp)) + \n",
    "    geom_violin()+\n",
    "    theme_bw()+\n",
    "    scale_fill_manual(values=c('#7fc97f','#beaed4','#fdc086','#ffff99'))+\n",
    "    ylab('Proportion of shared ASVs')#\n",
    "#ggsave(Figure1B, file = file.path(paste0(OUTDIR,'/figures/Fig_propsharedASVs.pdf')))\n",
    "#\n",
    "print(c('diff_spec_diff_site mean', mean(Figure1B_data$prop_shared[Figure1B_data$sp_site_comp=='diff_spec_diff_site'])))\n",
    "print(c('diff_spec_same_site mean', mean(Figure1B_data$prop_shared[Figure1B_data$sp_site_comp=='diff_spec_same_site'])))\n",
    "print(c('same_spec_diff_site', mean(Figure1B_data$prop_shared[Figure1B_data$sp_site_comp=='same_spec_diff_site'])))\n",
    "print(c('same_spec_same_site',mean(Figure1B_data$prop_shared[Figure1B_data$sp_site_comp=='same_spec_same_site'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Determine proportion of shared ASVs by bacterial order (Figure 1C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Clostridiales', 'Bacteroidales', 'Mollicutes_RF39',\n",
      "       'Erysipelotrichales', 'Spirochaetales', 'Gastranaerophilales',\n",
      "       'Selenomonadales', 'Betaproteobacteriales', 'Coriobacteriales',\n",
      "       'Lactobacillales'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(asv_16s[asv_16s['CP_pres']==True]['Order'].value_counts()[:10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_shared_by_order(order):\n",
    "    pw_df = pw_metadata_capt_samples(metadata_file)\n",
    "    asv_table_tax = add_tax_to_asv_table(asv_table_file,tax_table_file)\n",
    "    asv_table_order = asv_table_tax[asv_table_tax['Order']==order]\n",
    "    shared_ASV_all_genera = pw_df.apply(lambda row: \n",
    "                    shared_ASVs_common_gen(row['ind1'],row['ind2'],asv_table_order),axis=1)\n",
    "    pw_shared_ASV_all_genera = pw_df.merge(shared_ASV_all_genera,on=['ind1','ind2']) \n",
    "    pw_shared_ASV_all_genera['order']=order\n",
    "    return(pw_shared_ASV_all_genera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clostridales = prop_shared_by_order('Clostridiales')\n",
    "Bacteroidales = prop_shared_by_order('Bacteroidales')\n",
    "Mollicutes_RF39 = prop_shared_by_order('Mollicutes_RF39')\n",
    "Erysipelotrichales = prop_shared_by_order('Erysipelotrichales')\n",
    "Spirochaetales = prop_shared_by_order('Spirochaetales')\n",
    "Gastranaerophilales = prop_shared_by_order('Gastranaerophilales')\n",
    "Selenomonadales = prop_shared_by_order('Selenomonadales')\n",
    "Betaproteobacteriales = prop_shared_by_order('Selenomonadales')\n",
    "Coriobacteriales = prop_shared_by_order('Coriobacteriales')\n",
    "Lactobacillales = prop_shared_by_order('Lactobacillales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_shared_ASV_all_genera['order']='all'\n",
    "pw_shared_ASV_top10_gen = pd.concat([pw_shared_ASV_all_genera,Clostridales,Bacteroidales,\n",
    "                                     Mollicutes_RF39,Erysipelotrichales,Spirochaetales,\n",
    "                                     Gastranaerophilales,Selenomonadales,Betaproteobacteriales,\n",
    "                                     Coriobacteriales,Lactobacillales])\n",
    "pw_shared_ASV_top10_gen =  pw_shared_ASV_top10_gen[pw_shared_ASV_top10_gen['prop_shared']!='nan']\n",
    "pw_shared_ASV_top10_gen.to_csv(\n",
    "    'analyses/figures/16S_captive_Figure1C_data.txt',\n",
    "    sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_df = pw_metadata_capt_samples(metadata_file)\n",
    "asv_table_tax = add_tax_to_asv_table(asv_table_file,tax_table_file)\n",
    "Prevotella_genera = ['Prevotella','Prevotella_2','Prevotella_7','Prevotella_1', 'Prevotella_9']\n",
    "asv_table_Prevotella = asv_table_tax[asv_table_tax['Genus'].isin(Prevotella_genera)]\n",
    "shared_ASV_Prevotella = pw_df.apply(lambda row: \n",
    "    shared_ASVs_common_gen(row['ind1'],row['ind2'],asv_table_Prevotella),axis=1)\n",
    "pw_shared_ASV_Prevotella = pw_df.merge(shared_ASV_Prevotella,on=['ind1','ind2']) \n",
    "pw_shared_ASV_Prevotella.to_csv(\n",
    "    'analyses/figures/16S_captive_FigureS3_Prevotella_data.txt',\n",
    "    sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_summary_table(asv_hr_table_output):\n",
    "     #create summary table\n",
    "    all_asvs = pd.Series(asv_hr_table_output['HR_type'].value_counts(),name='ALL')\n",
    "    cp_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['CP_pres']==True]['HR_type'].value_counts(),name='CP')\n",
    "    Bacteroidales_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['Order']=='Bacteroidales']['HR_type'].value_counts(),name='Bacteroidales')\n",
    "    Bacteroides_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['Genus']=='Bacteroides']['HR_type'].value_counts(),name='Bacteroides')\n",
    "    Prevotella_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['Genus'].isin(Prevotella_genera)]['HR_type'].value_counts(),name='Prevotella')\n",
    "    Parabacteroides_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['Genus']=='Parabacteroides']['HR_type'].value_counts(),name='Parabacteroides')\n",
    "    Bifidobacteriales_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['Order']=='Bifidobacteriales']['HR_type'].value_counts(),name='Bifidobacteriales')\n",
    "    Bifidobacterium_asvs = pd.Series(asv_hr_table_output[asv_hr_table_output['Genus']=='Bifidobacterium']['HR_type'].value_counts(),name='Bifidobacterium')\n",
    "    res = pd.concat([all_asvs,cp_asvs,Bacteroidales_asvs,\n",
    "                     Bacteroides_asvs,Prevotella_asvs,Parabacteroides_asvs,\n",
    "                     Bifidobacteriales_asvs,Bifidobacterium_asvs],axis=1).fillna(0).T\n",
    "    res = res[['HR_human','HR_wild_bonobo','HR_wild_chimp','HR_wild_gorilla',\n",
    "         'MX_2_wild_apes','MX_3_wild_apes',\n",
    "         'MX_human_single_wild_ape','MX_human_2_wild_apes',\n",
    "         'MX_4_hominids','Unique_CP']]\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_human</th>\n",
       "      <th>HR_wild_bonobo</th>\n",
       "      <th>HR_wild_chimp</th>\n",
       "      <th>HR_wild_gorilla</th>\n",
       "      <th>MX_total</th>\n",
       "      <th>Unique_CP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>553.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacteroidales</th>\n",
       "      <td>211.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacteroides</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevotella</th>\n",
       "      <td>63.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parabacteroides</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bifidobacteriales</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bifidobacterium</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HR_human  HR_wild_bonobo  HR_wild_chimp  HR_wild_gorilla  \\\n",
       "ALL                   553.0            57.0          105.0            210.0   \n",
       "CP                    227.0             0.0           10.0              8.0   \n",
       "Bacteroidales         211.0            22.0           50.0             34.0   \n",
       "Bacteroides            33.0             0.0            0.0              0.0   \n",
       "Prevotella             63.0             5.0           15.0              8.0   \n",
       "Parabacteroides         6.0             1.0            0.0              0.0   \n",
       "Bifidobacteriales       3.0             0.0            0.0              0.0   \n",
       "Bifidobacterium         3.0             0.0            0.0              0.0   \n",
       "\n",
       "                   MX_total  Unique_CP  \n",
       "ALL                   946.0      106.0  \n",
       "CP                    520.0      106.0  \n",
       "Bacteroidales          88.0       29.0  \n",
       "Bacteroides            16.0        0.0  \n",
       "Prevotella             16.0        4.0  \n",
       "Parabacteroides         9.0        0.0  \n",
       "Bifidobacteriales       4.0        0.0  \n",
       "Bifidobacterium         4.0        0.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asv_16s_summary = output_summary_table(asv_16s)\n",
    "asv_16s_summary['MX_total'] = asv_16s_summary.loc[:,'MX_2_wild_apes':'MX_4_hominids'].sum(axis=1)\n",
    "Table1 = asv_16s_summary[['HR_human','HR_wild_bonobo','HR_wild_chimp','HR_wild_gorilla',\n",
    "                         'MX_total','Unique_CP']]Table1.to_csv(\n",
    "    'analyses/tables/Table1_raw.txt',\n",
    "    sep='\\t',index=False)\n",
    "Table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL                  925.0\n",
      "CP                   245.0\n",
      "Bacteroidales        317.0\n",
      "Bacteroides           33.0\n",
      "Prevotella            91.0\n",
      "Parabacteroides        7.0\n",
      "Bifidobacteriales      3.0\n",
      "Bifidobacterium        3.0\n",
      "dtype: float64\n",
      "ALL                  946.0\n",
      "CP                   520.0\n",
      "Bacteroidales         88.0\n",
      "Bacteroides           16.0\n",
      "Prevotella            16.0\n",
      "Parabacteroides        9.0\n",
      "Bifidobacteriales      4.0\n",
      "Bifidobacterium        4.0\n",
      "dtype: float64\n",
      "ALL                  331.0\n",
      "CP                    39.0\n",
      "Bacteroidales         32.0\n",
      "Bacteroides            0.0\n",
      "Prevotella             5.0\n",
      "Parabacteroides        1.0\n",
      "Bifidobacteriales      0.0\n",
      "Bifidobacterium        0.0\n",
      "dtype: float64\n",
      "ALL                  615.0\n",
      "CP                   481.0\n",
      "Bacteroidales         56.0\n",
      "Bacteroides           16.0\n",
      "Prevotella            11.0\n",
      "Parabacteroides        8.0\n",
      "Bifidobacteriales      4.0\n",
      "Bifidobacterium        4.0\n",
      "dtype: float64\n",
      "0.6951672862453532\n",
      "0.8152866242038217\n",
      "0.8783068783068783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR_human</th>\n",
       "      <th>HR_wild_bonobo</th>\n",
       "      <th>HR_wild_chimp</th>\n",
       "      <th>HR_wild_gorilla</th>\n",
       "      <th>MX_2_wild_apes</th>\n",
       "      <th>MX_3_wild_apes</th>\n",
       "      <th>MX_human_single_wild_ape</th>\n",
       "      <th>MX_human_2_wild_apes</th>\n",
       "      <th>MX_4_hominids</th>\n",
       "      <th>Unique_CP</th>\n",
       "      <th>MX_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALL</th>\n",
       "      <td>553.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CP</th>\n",
       "      <td>227.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacteroidales</th>\n",
       "      <td>211.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacteroides</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevotella</th>\n",
       "      <td>63.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parabacteroides</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bifidobacteriales</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bifidobacterium</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HR_human  HR_wild_bonobo  HR_wild_chimp  HR_wild_gorilla  \\\n",
       "ALL                   553.0            57.0          105.0            210.0   \n",
       "CP                    227.0             0.0           10.0              8.0   \n",
       "Bacteroidales         211.0            22.0           50.0             34.0   \n",
       "Bacteroides            33.0             0.0            0.0              0.0   \n",
       "Prevotella             63.0             5.0           15.0              8.0   \n",
       "Parabacteroides         6.0             1.0            0.0              0.0   \n",
       "Bifidobacteriales       3.0             0.0            0.0              0.0   \n",
       "Bifidobacterium         3.0             0.0            0.0              0.0   \n",
       "\n",
       "                   MX_2_wild_apes  MX_3_wild_apes  MX_human_single_wild_ape  \\\n",
       "ALL                         227.0           104.0                     269.0   \n",
       "CP                           20.0            19.0                     187.0   \n",
       "Bacteroidales                24.0             8.0                      50.0   \n",
       "Bacteroides                   0.0             0.0                      13.0   \n",
       "Prevotella                    3.0             2.0                      11.0   \n",
       "Parabacteroides               0.0             1.0                       8.0   \n",
       "Bifidobacteriales             0.0             0.0                       1.0   \n",
       "Bifidobacterium               0.0             0.0                       1.0   \n",
       "\n",
       "                   MX_human_2_wild_apes  MX_4_hominids  Unique_CP  MX_total  \n",
       "ALL                               157.0          189.0      106.0     946.0  \n",
       "CP                                128.0          166.0      106.0     520.0  \n",
       "Bacteroidales                       4.0            2.0       29.0      88.0  \n",
       "Bacteroides                         2.0            1.0        0.0      16.0  \n",
       "Prevotella                          0.0            0.0        4.0      16.0  \n",
       "Parabacteroides                     0.0            0.0        0.0       9.0  \n",
       "Bifidobacteriales                   1.0            2.0        0.0       4.0  \n",
       "Bifidobacterium                     1.0            2.0        0.0       4.0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(asv_16s_summary.loc[:,'HR_human':'HR_wild_gorilla'].sum(axis=1))\n",
    "print(asv_16s_summary.loc[:,'MX_2_wild_apes':'MX_4_hominids'].sum(axis=1))\n",
    "print(asv_16s_summary.loc[:,'MX_2_wild_apes':'MX_3_wild_apes'].sum(axis=1))\n",
    "print(asv_16s_summary.loc[:,'MX_human_single_wild_ape':'MX_4_hominids'].sum(axis=1))\n",
    "print(asv_16s_summary.loc['CP','MX_human_single_wild_ape']/asv_16s_summary.loc['ALL','MX_human_single_wild_ape'])\n",
    "print(asv_16s_summary.loc['CP','MX_human_2_wild_apes']/asv_16s_summary.loc['ALL','MX_human_2_wild_apes'])\n",
    "print(asv_16s_summary.loc['CP','MX_4_hominids']/asv_16s_summary.loc['ALL','MX_4_hominids'])\n",
    "asv_16s_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ete]",
   "language": "python",
   "name": "conda-env-ete-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
