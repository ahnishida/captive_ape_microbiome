{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'ASVs_filtered.fasta',\n",
       " 'ASVs_filtered_counts.tsv',\n",
       " 'ASVs_filtered_ref_amp.tree',\n",
       " 'ASVs_filtered_ref_full.tree',\n",
       " 'ASVs_taxonomy.txt',\n",
       " 'codiv_Bacteroidaceae.fna',\n",
       " 'metadata_gyrb_amp_meta_passing_samples.txt',\n",
       " 'ref_gyrb_gtdbtk',\n",
       " 'test.tre']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ete3 import Tree\n",
    "from collections import Counter\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/Volumes/AHN/captive_ape_microbiome/results/gyrb/')\n",
    "\n",
    "os.listdir('inputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "metadata_file = 'inputs/metadata_gyrb_amp_meta_passing_samples.txt'\n",
    "tax_table_file = 'inputs/ASVs_taxonomy.txt'\n",
    "asv_table_file = 'inputs/ASVs_filtered_counts.tsv'\n",
    "asv_fasta_file = 'inputs/ASVs_filtered.fasta'\n",
    "tree_file = 'inputs/ASVs_filtered_ref_full.tree'\n",
    "moeller_codiv_fasta = 'inputs/codiv_Bacteroidaceae.fna'\n",
    "pident_cutoff = 95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blastn moeller co-div seqs against ASVs and filter ASVs matchin X% identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 07/21/2020 12:33:43\n",
      "New DB name:   /Volumes/AHN/captive_ape_microbiome/results/gyrb/analyses/codiv_moeller_ASVs/codiv_Bacteroidaceae.fna\n",
      "New DB title:  analyses/codiv_moeller_ASVs/codiv_Bacteroidaceae.fna\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /Volumes/AHN/captive_ape_microbiome/results/gyrb/analyses/codiv_moeller_ASVs/codiv_Bacteroidaceae.fna\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 208 sequences in 0.0233161 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: analyses/codiv_moeller_ASVs: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir analyses/codiv_moeller_ASVs\n",
    "cp inputs/codiv_Bacteroidaceae.fna analyses/codiv_moeller_ASVs/codiv_Bacteroidaceae.fna\n",
    "\n",
    "#make blastdb\n",
    "makeblastdb -in analyses/codiv_moeller_ASVs/codiv_Bacteroidaceae.fna -dbtype nucl\n",
    "\n",
    "#blast moeller co-div seqs\n",
    "blastn -query inputs/ASVs_filtered.fasta -db analyses/codiv_moeller_ASVs/codiv_Bacteroidaceae.fna \\\n",
    "-outfmt \"7 qseqid salltitles sseqid pident length qlen evalue\" \\\n",
    "-out analyses/codiv_moeller_ASVs/codiv_blastout_ASVs.txt \\\n",
    "-max_target_seqs 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the matching ASVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n",
      "314 ASVs matching co-div clades with greater than 95 percent identity\n",
      "Bt1 lineage\n",
      "41 ASVs identified in blast search but 41 ASVs are within the monophyletic clade\n",
      "Bt2 lineage\n",
      "156 ASVs identified in blast search but 360 ASVs are within the monophyletic clade\n",
      "Bt3 lineage\n",
      "117 ASVs identified in blast search but 586 ASVs are within the monophyletic clade\n"
     ]
    }
   ],
   "source": [
    "#filter blast output to top hit per ASV, remove hits not pass thresholds\n",
    "blast_res = pd.read_csv('analyses/codiv_moeller_ASVs/codiv_blastout_ASVs.txt',sep='\\t',comment='#',header=None)\n",
    "blast_res.columns = ['ASV','codiv_clade_seq','sseqid','pident','length','qlen','evalue']\n",
    "blast_res = blast_res.groupby('ASV').head(1).reset_index(drop=True) #get top hit\n",
    "blast_res_pass = blast_res[blast_res['pident']>pident_cutoff].reset_index(drop=True)\n",
    "print(len(blast_res_pass))\n",
    "blast_res_pass = blast_res_pass[blast_res_pass['length']>200].reset_index(drop=True)\n",
    "print(len(blast_res_pass),'ASVs matching co-div clades with greater than',pident_cutoff,'percent identity')\n",
    "blast_res_pass['codiv_clade'] = blast_res_pass['codiv_clade_seq'].apply(lambda x: x.split(' ')[1])\n",
    "blast_res_pass['lineage'] = blast_res_pass['codiv_clade'].apply(lambda x: x.split('_')[0]) \n",
    "blast_res_pass = blast_res_pass[['ASV', 'lineage', 'codiv_clade', 'codiv_clade_seq', 'sseqid', 'pident', 'length', 'qlen', 'evalue']]\n",
    "#output hits passing that will be used to determine the mcra of the lineage\n",
    "blast_res_pass.to_csv('analyses/codiv_moeller_ASVs/codiv_blastout_ASVs_passing.txt',sep='\\t',index=False)\n",
    "\n",
    "def get_lineage_ASVs(tree_file,listASVs):\n",
    "    tree = Tree(tree_file, format=0)\n",
    "    #makes sure we don't miss any ASVs that didn't match in the blast search \\n\"\n",
    "    #but are descended from the MRCA of those that did\\n\"\n",
    "    lineage_MRCA = tree.get_common_ancestor(listASVs)\n",
    "    lineageASVs = [x.name for x in lineage_MRCA.get_leaves()] \n",
    "    print(len(listASVs), 'ASVs identified in blast search but', len(lineageASVs), 'ASVs are within the monophyletic clade')\n",
    "    return(lineageASVs)\n",
    "\n",
    "print('Bt1 lineage')\n",
    "Bt1_blasthits_table = blast_res_pass[blast_res_pass['codiv_clade_seq'].apply(lambda x: 'Bt1' in x)]\n",
    "Bt1_blasthits_ASVs = list(Bt1_blasthits_table['ASV'])\n",
    "Bt1_lineage_ASVs = get_lineage_ASVs(\"inputs/ASVs_filtered_ref_full.tree\",Bt1_blasthits_ASVs)\n",
    "Bt1_lineage_ASVs = pd.DataFrame(Bt1_lineage_ASVs,columns=['ASV'])\n",
    "Bt1_lineage_ASVs_merged = Bt1_lineage_ASVs.merge(blast_res_pass,on='ASV',how='left')\n",
    "Bt1_lineage_ASVs_merged['lineage'] = 'Bt1'\n",
    "print('Bt2 lineage') \n",
    "Bt2_blasthits_table = blast_res_pass[blast_res_pass['codiv_clade_seq'].apply(lambda x: 'Bt2' in x)]\n",
    "Bt2_blasthits_ASVs = list(Bt2_blasthits_table['ASV'])\n",
    "Bt2_lineage_ASVs = get_lineage_ASVs(\"inputs/ASVs_filtered_ref_full.tree\",Bt2_blasthits_ASVs)\n",
    "Bt2_lineage_ASVs = pd.DataFrame(Bt2_lineage_ASVs,columns=['ASV'])\n",
    "Bt2_lineage_ASVs_merged = Bt2_lineage_ASVs.merge(blast_res_pass,on='ASV',how='left')\n",
    "Bt2_lineage_ASVs_merged['lineage'] = 'Bt2'\n",
    "print('Bt3 lineage') \n",
    "Bt3_blasthits_table = blast_res_pass[blast_res_pass['codiv_clade_seq'].apply(lambda x: 'Bt3' in x)]\n",
    "Bt3_blasthits_ASVs = list(Bt3_blasthits_table['ASV'])\n",
    "Bt3_lineage_ASVs = get_lineage_ASVs(\"inputs/ASVs_filtered_ref_full.tree\",Bt3_blasthits_ASVs)\n",
    "Bt3_lineage_ASVs = pd.DataFrame(Bt3_lineage_ASVs,columns=['ASV'])\n",
    "Bt3_lineage_ASVs_merged = Bt3_lineage_ASVs.merge(blast_res_pass,on='ASV',how='left')\n",
    "Bt3_lineage_ASVs_merged['lineage'] = 'Bt3'\n",
    "\n",
    "#append table to output single file\n",
    "codiv_clades = pd.concat([Bt1_lineage_ASVs_merged,Bt2_lineage_ASVs_merged,Bt3_lineage_ASVs_merged])\n",
    "codiv_clades.to_csv('analyses/codiv_moeller_ASVs/codiv_clades_ASVs.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f__Bacteroidaceaeg__Bacteroides_B\n"
     ]
    }
   ],
   "source": [
    "#generates three dictionaries where keys are ASVs, and values are metadata\n",
    "#all the samples with a given ASV\n",
    "#all the sample types with a given ASV per metadata info\n",
    "#taxonomic info, family and genus\n",
    "\n",
    "metadata = pd.read_csv(metadata_file,sep='\\t',index_col=None)\n",
    "sample_type_dict = dict(zip(metadata['X.SampleID'], metadata['Description']))\n",
    "\n",
    "tax_table = pd.read_csv(tax_table_file,sep='\\t',index_col=0)\n",
    "tax_table['FamilyGenus'] = tax_table['Family'] + tax_table['Genus']\n",
    "ASV_taxonomy_dict = dict(zip(tax_table.index, tax_table['FamilyGenus']))\n",
    "print(ASV_taxonomy_dict[\"ASV_1\"])\n",
    "\n",
    "ASV_sampleName_dict = {}  \n",
    "asv_table = pd.read_csv(asv_table_file,sep='\\t',index_col=0)\n",
    "for ASV,row in asv_table.iterrows():\n",
    "    sampleNames = list(asv_table.columns[row>0])\n",
    "    ASV_sampleName_dict[ASV] = sampleNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ete/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 HR clades\n",
      "41 HR ASVs\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from pandas.core.common import flatten\n",
    "\n",
    "full_tree = Tree(\"inputs/ASVs_filtered_ref_amp.tree\", format=0)\n",
    "Bt1_tree = full_tree.get_common_ancestor(list(Bt1_lineage_ASVs['ASV']))\n",
    "\n",
    "def is_HR(sampleNames):\n",
    "    sampleTypes = [sample_type_dict[name] for name in sampleNames]\n",
    "    sampleTypes = [x.replace('non_western_','').replace('western_','') for x in sampleTypes]\n",
    "    neutral_sampleTypes = ['captive_gorilla','captive_bonobo','captive_chimp','captive_orangutan']\n",
    "    select_sampleTypes = [x for x in sampleTypes if x not in neutral_sampleTypes]\n",
    "    unique_sampleTypes = list(set(select_sampleTypes))\n",
    "    \n",
    "    if len(unique_sampleTypes) == 0:\n",
    "        return(unique_sampleTypes,'captive',len(sampleTypes))\n",
    "    if len(unique_sampleTypes)  == 1: #identifies host-restricted clades\n",
    "        HR_clade = select_sampleTypes[0]\n",
    "        HR_sample_num = len([t for t in sampleTypes if t == HR_clade])\n",
    "        return(unique_sampleTypes,unique_sampleTypes[0],HR_sample_num) #doesn't count captive ape samples\n",
    "    if len(unique_sampleTypes)  > 1:    \n",
    "        return(unique_sampleTypes,'mixed',len(sampleTypes))\n",
    "\n",
    "def search_clades(tree, samples_cutoff, BS_support):\n",
    "    \"\"\"Finds nodes with at least 50% BS support containing ASVs only found in a single wild ape species\n",
    "    ie wild_gorilla, wild_chimp or wild_bonobo\"\"\"\n",
    "    HR_clades_passing_thresholds = []\n",
    "    counter = 1\n",
    "    for n in tree.traverse():\n",
    "        if n.support > float(BS_support): #makes sure Bootstrap support is over threshold\n",
    "            ASVs = [leaf.name for leaf in n.iter_leaves() if 'ASV' in leaf.name]\n",
    "            ASVsNum = len(ASVs) \n",
    "            ASVsTax = list(set(list(flatten([ASV_taxonomy_dict[ASV] for ASV in ASVs]))))\n",
    "            sampleNames = list(set(list(flatten([ASV_sampleName_dict[ASV] for ASV in ASVs]))))\n",
    "            sampleNum = len(sampleNames)\n",
    "            sampleTypes,HR_clade,HR_sampleNum = is_HR(sampleNames)\n",
    "            if HR_sampleNum > samples_cutoff:\n",
    "                cladeName = 'clade_'+str(counter)\n",
    "                counter+=1\n",
    "                clade = [cladeName,HR_clade,HR_sampleNum,ASVs,ASVsNum,ASVsTax,sampleNames,sampleNum,sampleTypes]\n",
    "                HR_clades_passing_thresholds.append(clade)  \n",
    "    clades = pd.DataFrame(HR_clades_passing_thresholds, columns = \n",
    "                          ['cladeName','HR_clade','HR_sampleNum',\n",
    "                           'ASV','ASVsNum','ASVsTax',\n",
    "                           'sampleNames','sampleNum','sampleTypes'])\n",
    "    return(clades)\n",
    "\n",
    "#initial search contains all sub clades within the largest host restricted clade\n",
    "clades_Bt1 = search_clades(Bt1_tree,samples_cutoff=5,BS_support=.5) \n",
    "#print(len(clades_Bt1))\n",
    "HRclades_Bt1 = clades_Bt1[clades_Bt1['HR_clade']!='mixed'][clades_Bt1['HR_clade']!='captive']     \n",
    "MXclades_Bt1 = clades_Bt1[clades_Bt1['HR_clade']=='mixed']\n",
    "CPclades_Bt1 = clades_Bt1[clades_Bt1['HR_clade']=='captive']\n",
    "#print(len(HRclades_Bt1),len(MXclades_Bt1),len(CPclades_Bt1))\n",
    "\n",
    "def eliminate_redundant_clades(search_clades_res):\n",
    "    df = search_clades_res.sort_values('ASVsNum',ascending=False) #start with the largest clades first\n",
    "    NRclades = []\n",
    "    NR_ASVs = []\n",
    "    for index, row in df.iterrows():\n",
    "        firstASV = row['ASV'][0]    \n",
    "        if firstASV not in NR_ASVs:\n",
    "            NR_ASVs = NR_ASVs + row['ASV']\n",
    "            NRclades.append(row['cladeName']) \n",
    "            #print(row['cladeName'])\n",
    "    res = df[df['cladeName'].isin(NRclades)]   \n",
    "    return(res)\n",
    "HRclades_Bt1 = eliminate_redundant_clades(HRclades_Bt1)\n",
    "HRclades_Bt1.to_csv('analyses/codiv_moeller_ASVs/HRclades_Bt1.txt',sep='\\t',index=False)\n",
    "print(len(HRclades_Bt1),'HR clades')\n",
    "\n",
    "def expand_clades(clades_df):\n",
    "    ASV = clades_df.apply(lambda x: pd.Series(x['ASV']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    ASV.name = 'ASV'\n",
    "    clades_ASVs_df = clades_df.drop('ASV', axis=1).join(ASV)\n",
    "    return(clades_ASVs_df)\n",
    "\n",
    "HRclades_Bt1_ASVs = expand_clades(HRclades_Bt1)\n",
    "print(len(HRclades_Bt1_ASVs),'HR ASVs')\n",
    "HRclades_Bt1_ASVs.to_csv('analyses/codiv_moeller_ASVs/HRclades_Bt1_ASVs.txt',sep='\\t',index=False)\n",
    "\n",
    "\n",
    "def is_unique_MX(HRclades_ASVs,cladeASVs):\n",
    "    overlapASVs = list(set(cladeASVs) & \n",
    "         set(HRclades_ASVs))\n",
    "    if len(overlapASVs) == 0:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "HRclades_ASVs = list(HRclades_Bt1_ASVs['ASV'])        \n",
    "MXclades_Bt1 = MXclades_Bt1[MXclades_Bt1['ASV'].apply(lambda cladeASVs: is_unique_MX(HRclades_ASVs,cladeASVs))]\n",
    "MXclades_Bt1 = eliminate_redundant_clades(MXclades_Bt1)\n",
    "MXclades_Bt1_ASVs = expand_clades(MXclades_Bt1)\n",
    "print(len(MXclades_Bt1_ASVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 total ASVs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ete/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/usr/local/anaconda3/envs/ete/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 HR clades\n",
      "     cladeName    HR_clade  HR_sampleNum  ASVsNum  \\\n",
      "4      clade_5       human           301       89   \n",
      "4      clade_5       human           301       89   \n",
      "4      clade_5       human           301       89   \n",
      "4      clade_5       human           301       89   \n",
      "4      clade_5       human           301       89   \n",
      "..         ...         ...           ...      ...   \n",
      "331  clade_332  wild_chimp            38        7   \n",
      "331  clade_332  wild_chimp            38        7   \n",
      "331  clade_332  wild_chimp            38        7   \n",
      "331  clade_332  wild_chimp            38        7   \n",
      "331  clade_332  wild_chimp            38        7   \n",
      "\n",
      "                                               ASVsTax  \\\n",
      "4    [f__Bacteroidaceaeg__Prevotella, f__Bacteroida...   \n",
      "4    [f__Bacteroidaceaeg__Prevotella, f__Bacteroida...   \n",
      "4    [f__Bacteroidaceaeg__Prevotella, f__Bacteroida...   \n",
      "4    [f__Bacteroidaceaeg__Prevotella, f__Bacteroida...   \n",
      "4    [f__Bacteroidaceaeg__Prevotella, f__Bacteroida...   \n",
      "..                                                 ...   \n",
      "331                   [f__Bacteroidaceaeg__Prevotella]   \n",
      "331                   [f__Bacteroidaceaeg__Prevotella]   \n",
      "331                   [f__Bacteroidaceaeg__Prevotella]   \n",
      "331                   [f__Bacteroidaceaeg__Prevotella]   \n",
      "331                   [f__Bacteroidaceaeg__Prevotella]   \n",
      "\n",
      "                                           sampleNames  sampleNum  \\\n",
      "4    [ZeeviD_2015__PNP_Main_247, VogtmannE_2016__MM...        301   \n",
      "4    [ZeeviD_2015__PNP_Main_247, VogtmannE_2016__MM...        301   \n",
      "4    [ZeeviD_2015__PNP_Main_247, VogtmannE_2016__MM...        301   \n",
      "4    [ZeeviD_2015__PNP_Main_247, VogtmannE_2016__MM...        301   \n",
      "4    [ZeeviD_2015__PNP_Main_247, VogtmannE_2016__MM...        301   \n",
      "..                                                 ...        ...   \n",
      "331  [wd.chi.GM.11.Bt, wd.chi.GM.1077.Bt, wd.chi.GM...         38   \n",
      "331  [wd.chi.GM.11.Bt, wd.chi.GM.1077.Bt, wd.chi.GM...         38   \n",
      "331  [wd.chi.GM.11.Bt, wd.chi.GM.1077.Bt, wd.chi.GM...         38   \n",
      "331  [wd.chi.GM.11.Bt, wd.chi.GM.1077.Bt, wd.chi.GM...         38   \n",
      "331  [wd.chi.GM.11.Bt, wd.chi.GM.1077.Bt, wd.chi.GM...         38   \n",
      "\n",
      "      sampleTypes       ASV  \n",
      "4         [human]  ASV_8449  \n",
      "4         [human]  ASV_7506  \n",
      "4         [human]  ASV_2654  \n",
      "4         [human]  ASV_2655  \n",
      "4         [human]  ASV_1185  \n",
      "..            ...       ...  \n",
      "331  [wild_chimp]   ASV_310  \n",
      "331  [wild_chimp]  ASV_1590  \n",
      "331  [wild_chimp]  ASV_1068  \n",
      "331  [wild_chimp]   ASV_712  \n",
      "331  [wild_chimp]  ASV_5978  \n",
      "\n",
      "[1028 rows x 9 columns]\n",
      "1028 HR ASVs\n",
      "45     [ASV_9751, ASV_6493, ASV_1682, ASV_6494, ASV_9...\n",
      "297             [ASV_1337, ASV_6211, ASV_6071, ASV_6156]\n",
      "Name: ASV, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Bt2_ASVs = list(Bt2_lineage_ASVs['ASV'])\n",
    "print(len(Bt2_ASVs),'total ASVs')\n",
    "Bt2_tree = full_tree.get_common_ancestor(Bt2_ASVs)\n",
    "clades_Bt2 = search_clades(Bt2_tree,samples_cutoff=5,BS_support=.5) \n",
    "#print(len(clades_Bt1))\n",
    "HRclades_Bt2 = clades_Bt2[clades_Bt2['HR_clade']!='mixed'][clades_Bt2['HR_clade']!='captive']     \n",
    "MXclades_Bt2 = clades_Bt2[clades_Bt2['HR_clade']=='mixed']\n",
    "CPclades_Bt2 = clades_Bt1[clades_Bt2['HR_clade']=='captive']\n",
    "HRclades_Bt2 = eliminate_redundant_clades(HRclades_Bt2)\n",
    "print(len(HRclades_Bt2),'HR clades')\n",
    "HRclades_Bt2_ASVs = expand_clades(HRclades_Bt2)\n",
    "HRclades_Bt2_ASVs.to_csv('analyses/codiv_moeller_ASVs/HRclades_Bt2_ASVs.txt',sep='\\t',index=False)\n",
    "\n",
    "print(HRclades_Bt2_ASVs)\n",
    "HRclades_ASVs = list(HRclades_Bt2_ASVs['ASV'])  \n",
    "print(len(HRclades_ASVs),'HR ASVs')\n",
    "\n",
    "      \n",
    "MXclades_Bt2 = MXclades_Bt2[MXclades_Bt2['ASV'].apply(lambda cladeASVs: is_unique_MX(HRclades_ASVs,cladeASVs))]\n",
    "MXclades_Bt2 = eliminate_redundant_clades(MXclades_Bt2)\n",
    "print(MXclades_Bt2['ASV'])\n",
    "MXclades_Bt2_ASVs = expand_clades(MXclades_Bt2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human           5625\n",
       "wild_bonobo      342\n",
       "wild_gorilla     168\n",
       "wild_chimp       111\n",
       "Name: HR_clade, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulltree = Tree(\"inputs/ASVs_filtered_ref_full.tree\", format=0)\n",
    "HRclades_fulltree = search_clades(fulltree,samples_cutoff=5,BS_support=.5) \n",
    "HRclades_fulltree = eliminate_redundant_clades(HRclades_fulltree)\n",
    "HRclades_fulltree.to_csv('analyses/codiv_moeller_ASVs/HRclades_fulltree.txt',sep='\\t',index=False)\n",
    "HRclades_fulltree_ASVs = expand_clades(HRclades_fulltree)\n",
    "HRclades_fulltree_ASVs.to_csv('analyses/codiv_moeller_ASVs/HRclades_fulltree_ASVs.txt',sep='\\t',index=False)\n",
    "HRclades_fulltree_ASVs['HR_clade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables summarizing metadata of samples harboring ASVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       western_human  non_western_human  captive_chimp  captive_gorilla  \\\n",
      "ASV_1         2917.0               64.0            3.0              2.0   \n",
      "ASV_2         2074.0               14.0            9.0              5.0   \n",
      "ASV_3         1907.0               17.0            1.0              2.0   \n",
      "ASV_4         1798.0               18.0            0.0              0.0   \n",
      "ASV_5         1208.0               18.0            0.0              2.0   \n",
      "\n",
      "       wild_chimp  captive_bonobo  captive_orangutan  wild_bonobo  \\\n",
      "ASV_1         1.0             1.0                0.0          0.0   \n",
      "ASV_2         9.0             0.0                4.0          0.0   \n",
      "ASV_3         1.0             2.0                0.0          0.0   \n",
      "ASV_4         1.0             0.0                0.0          0.0   \n",
      "ASV_5        18.0             2.0                4.0          0.0   \n",
      "\n",
      "       wild_gorilla  \n",
      "ASV_1           0.0  \n",
      "ASV_2           0.0  \n",
      "ASV_3           0.0  \n",
      "ASV_4           0.0  \n",
      "ASV_5           0.0  \n",
      "western_human        6805\n",
      "non_western_human     511\n",
      "wild_chimp             69\n",
      "wild_gorilla           37\n",
      "captive_chimp          26\n",
      "wild_bonobo            24\n",
      "captive_gorilla        22\n",
      "captive_bonobo         13\n",
      "captive_orangutan      11\n",
      "Name: Description, dtype: int64\n",
      "       captive_bonobo  captive_chimp  captive_gorilla  captive_orangutan  \\\n",
      "ASV_1        0.076923       0.115385         0.090909           0.000000   \n",
      "ASV_2        0.000000       0.346154         0.227273           0.363636   \n",
      "ASV_3        0.153846       0.038462         0.090909           0.000000   \n",
      "ASV_4        0.000000       0.000000         0.000000           0.000000   \n",
      "ASV_5        0.153846       0.000000         0.090909           0.363636   \n",
      "\n",
      "       non_western_human  western_human  wild_bonobo  wild_chimp  wild_gorilla  \n",
      "ASV_1           0.125245       0.428655          0.0    0.014493           0.0  \n",
      "ASV_2           0.027397       0.304776          0.0    0.130435           0.0  \n",
      "ASV_3           0.033268       0.280235          0.0    0.014493           0.0  \n",
      "ASV_4           0.035225       0.264217          0.0    0.014493           0.0  \n",
      "ASV_5           0.035225       0.177517          0.0    0.260870           0.0  \n"
     ]
    }
   ],
   "source": [
    "#creates table where ASVs are rows, columns are sample descriptions (i.e wild_chimp, captive_orangutan)\n",
    "#counts are the number of samples or the percent of samples of a given type over the total number of samples belong to that type\n",
    "\n",
    "sample_type_num = pd.DataFrame()\n",
    "for ASV in ASV_sampleName_dict:\n",
    "        sample_names = ASV_sampleName_dict[ASV]\n",
    "        #sample_type_dict relates sample names to their descriptions \n",
    "        sample_types = [sample_type_dict[name] for name in sample_names]\n",
    "        sample_types = pd.Series(sample_types).value_counts()\n",
    "        row = pd.DataFrame(sample_types)\n",
    "        sample_type_num = pd.concat([sample_type_num, row], axis=1, sort=False)\n",
    "sample_type_num.columns = ASV_sampleName_dict.keys()\n",
    "sample_type_num = sample_type_num.T \n",
    "sample_type_num = sample_type_num.fillna(0)\n",
    "print(sample_type_num.head())\n",
    "sample_type_num.to_csv('analyses/codiv_moeller_ASVs/Table_sampletypes_ASV_count.txt',sep='\\t',index=False)\n",
    "sample_type_counts =  metadata['Description'].value_counts()\n",
    "print(sample_type_counts)\n",
    "sample_type_perc = sample_type_num/sample_type_counts \n",
    "print(sample_type_perc.head())\n",
    "sample_type_perc.to_csv('analyses/codiv_moeller_ASVs/Table_sampletypes_ASV_perc.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       western_human_CHN  western_human_DNK  western_human_USA  \\\n",
      "ASV_1              571.0              278.0              269.0   \n",
      "ASV_2              382.0              255.0              134.0   \n",
      "ASV_3              447.0              229.0              174.0   \n",
      "ASV_4              366.0              179.0              160.0   \n",
      "ASV_5              265.0               94.0              128.0   \n",
      "\n",
      "       western_human_SWE  western_human_ISR  western_human_ESP  \\\n",
      "ASV_1              233.0              220.0              204.0   \n",
      "ASV_2              203.0              160.0              141.0   \n",
      "ASV_3              177.0              121.0              129.0   \n",
      "ASV_4              130.0              212.0              128.0   \n",
      "ASV_5              172.0               26.0               44.0   \n",
      "\n",
      "       western_human_NLD  western_human_DEU  western_human_GBR  \\\n",
      "ASV_1              194.0              165.0              137.0   \n",
      "ASV_2              111.0              124.0              126.0   \n",
      "ASV_3               49.0              124.0              119.0   \n",
      "ASV_4              121.0               94.0              137.0   \n",
      "ASV_5               12.0               41.0               68.0   \n",
      "\n",
      "       western_human_FIN  ...  western_human_HUN  wild_gorilla_EK  \\\n",
      "ASV_1              127.0  ...                0.0              0.0   \n",
      "ASV_2               88.0  ...                0.0              0.0   \n",
      "ASV_3               79.0  ...                0.0              0.0   \n",
      "ASV_4               37.0  ...                0.0              0.0   \n",
      "ASV_5              109.0  ...                0.0              0.0   \n",
      "\n",
      "       non_western_human_TZA  wild_gorilla_CP  wild_gorilla_DG  wild_chimp_DG  \\\n",
      "ASV_1                    0.0              0.0              0.0            0.0   \n",
      "ASV_2                    0.0              0.0              0.0            0.0   \n",
      "ASV_3                    0.0              0.0              0.0            0.0   \n",
      "ASV_4                    0.0              0.0              0.0            0.0   \n",
      "ASV_5                    0.0              0.0              0.0            0.0   \n",
      "\n",
      "       wild_chimp_CP  wild_bonobo_LK  wild_bonobo_KR  wild_gorilla_LB  \n",
      "ASV_1            0.0             0.0             0.0              0.0  \n",
      "ASV_2            0.0             0.0             0.0              0.0  \n",
      "ASV_3            0.0             0.0             0.0              0.0  \n",
      "ASV_4            0.0             0.0             0.0              0.0  \n",
      "ASV_5            0.0             0.0             0.0              0.0  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "western_human        6805\n",
      "non_western_human     511\n",
      "wild_chimp             69\n",
      "wild_gorilla           37\n",
      "captive_chimp          26\n",
      "wild_bonobo            24\n",
      "captive_gorilla        22\n",
      "captive_bonobo         13\n",
      "captive_orangutan      11\n",
      "Name: Description, dtype: int64\n",
      "       captive_bonobo_COLZ  captive_chimp_HOUZ  captive_chimp_PC  \\\n",
      "ASV_1             0.076923            0.333333          0.000000   \n",
      "ASV_2             0.000000            0.555556          0.235294   \n",
      "ASV_3             0.153846            0.111111          0.000000   \n",
      "ASV_4             0.000000            0.000000          0.000000   \n",
      "ASV_5             0.153846            0.000000          0.000000   \n",
      "\n",
      "       captive_gorilla_COLZ  captive_gorilla_HOUZ  captive_orangutan_COLZ  \\\n",
      "ASV_1              0.071429                 0.125                     0.0   \n",
      "ASV_2              0.071429                 0.500                     0.5   \n",
      "ASV_3              0.142857                 0.000                     0.0   \n",
      "ASV_4              0.000000                 0.000                     0.0   \n",
      "ASV_5              0.142857                 0.000                     0.0   \n",
      "\n",
      "       captive_orangutan_HOUZ  non_western_human_FJI  non_western_human_MDG  \\\n",
      "ASV_1                0.000000               0.149194               0.009524   \n",
      "ASV_2                0.285714               0.024194               0.019048   \n",
      "ASV_3                0.000000               0.008065               0.019048   \n",
      "ASV_4                0.000000               0.024194               0.019048   \n",
      "ASV_5                0.571429               0.012097               0.038095   \n",
      "\n",
      "       non_western_human_MNG  ...  wild_chimp_EK  wild_chimp_GM  \\\n",
      "ASV_1               0.400000  ...            0.0       0.020833   \n",
      "ASV_2               0.092308  ...            0.5       0.145833   \n",
      "ASV_3               0.200000  ...            0.0       0.000000   \n",
      "ASV_4               0.153846  ...            0.0       0.020833   \n",
      "ASV_5               0.169231  ...            0.0       0.354167   \n",
      "\n",
      "       wild_chimp_LU  wild_chimp_OP  wild_gorilla_CP  wild_gorilla_DG  \\\n",
      "ASV_1            0.0          0.000              0.0              0.0   \n",
      "ASV_2            0.0          0.125              0.0              0.0   \n",
      "ASV_3            0.0          0.125              0.0              0.0   \n",
      "ASV_4            0.0          0.000              0.0              0.0   \n",
      "ASV_5            0.0          0.125              0.0              0.0   \n",
      "\n",
      "       wild_gorilla_EK  wild_gorilla_LB  wild_gorilla_LU  wild_gorilla_OP  \n",
      "ASV_1              0.0              0.0              0.0              0.0  \n",
      "ASV_2              0.0              0.0              0.0              0.0  \n",
      "ASV_3              0.0              0.0              0.0              0.0  \n",
      "ASV_4              0.0              0.0              0.0              0.0  \n",
      "ASV_5              0.0              0.0              0.0              0.0  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "#creates table where ASVs are rows, columns are sample descriptions plus site \n",
    "#counts are the number of samples or the percent of samples of a given type over the total number of samples belong to that type\n",
    "\n",
    "metadata['Description_site'] = metadata['Description']+'_' +metadata['site_code']\n",
    "sample_type_site_dict = dict(zip(metadata['X.SampleID'], metadata['Description_site']))\n",
    "\n",
    "captive_only_desc = list(set(metadata['Description_site']))\n",
    "captive_only_desc = [desc for desc in captive_only_desc if 'captive' in str(desc)]\n",
    "captive_only_desc\n",
    "\n",
    "sample_type_site_num = pd.DataFrame()\n",
    "for ASV in ASV_sampleName_dict:\n",
    "        sample_names = ASV_sampleName_dict[ASV]\n",
    "        sample_types = [sample_type_site_dict[name] for name in sample_names]\n",
    "        sample_types = pd.Series(sample_types).value_counts()\n",
    "        row = pd.DataFrame(sample_types)\n",
    "        sample_type_site_num = pd.concat([sample_type_site_num, row], axis=1, sort=False)\n",
    "sample_type_site_num.columns = ASV_sampleName_dict.keys()\n",
    "sample_type_site_num = sample_type_site_num.T \n",
    "sample_type_site_num = sample_type_site_num.fillna(0)\n",
    "print(sample_type_site_num.head())\n",
    "sample_type_site_num.to_csv('analyses/codiv_moeller_ASVs/Table_sampletypes_site_ASV_count.txt',sep='\\t',index=False)\n",
    "sample_type_site_counts =  metadata['Description_site'].value_counts()\n",
    "print(sample_type_counts)\n",
    "sample_type_site_perc = sample_type_site_num/sample_type_site_counts \n",
    "print(sample_type_site_perc.head())\n",
    "sample_type_site_perc.to_csv('analyses/codiv_moeller_ASVs/Table_sampletypes_site_ASV_perc.txt',sep='\\t',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_type_site_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-59555d89442a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#subset to just captive ape descriptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_type_site_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_type_site_num_just_captive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_type_site_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcaptive_only_desc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_type_site_num_just_captive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ASV'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msample_type_site_num_just_captive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_type_site_num' is not defined"
     ]
    }
   ],
   "source": [
    "#subset to just captive ape descriptions\n",
    "sample_type_site_num.columns\n",
    "sample_type_site_num_just_captive = sample_type_site_num[captive_only_desc]\n",
    "sample_type_site_num_just_captive.index.name = 'ASV'\n",
    "sample_type_site_num_just_captive.reset_index(inplace=True)\n",
    "sample_type_site_num_just_captive.to_csv('analyses/codiv_moeller_ASVs/Table_sampletypes_site_captive_ASV_count.txt',sep='\\t',index=False)\n",
    "sample_type_site_perc_just_captive = sample_type_site_perc[captive_only_desc]\n",
    "sample_type_site_perc_just_captive.index.name = 'ASV'\n",
    "sample_type_site_perc_just_captive.reset_index(inplace=True)\n",
    "sample_type_site_perc_just_captive.to_csv('analyses/codiv_moeller_ASVs/Table_sampletypes_site_captive_ASV_perc.txt',sep='\\t',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ete]",
   "language": "python",
   "name": "conda-env-ete-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
