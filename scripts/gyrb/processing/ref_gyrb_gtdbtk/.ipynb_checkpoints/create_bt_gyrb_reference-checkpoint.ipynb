{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to search GTDB-Tk reference genome for gyrase B sequences to be able to assign species-level taxonomy to gyraseB amplicon data. Genomes are annotated using Prodigal, then gyraseB sequences are filtered out using a HMM profile of gyrase B from the TIGR01059 profile in the individual hmms folder. Then nucleotide and protein sequences are output to fastas. These fastas will be used as reference databases for local blast searches used to assign taxonomy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio import Seq\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/Volumes/AHN/captive_ape_microbiome')\n",
    "#create output folders\n",
    "outdir= 'results/gyrb_bt_gtdbtk_ref'\n",
    "os.system('mkdir -pv '+outdir+'/hmm_out')\n",
    "os.system('mkdir -pv '+outdir+'/prodigal')\n",
    "os.system('mkdir -pv '+outdir+'/gyrb_seqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24706"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in taxonomy file\n",
    "tax = pd.read_csv('ref_seqs/GTDBTK_db/taxonomy/gtdb_taxonomy.tsv',sep='\\t',header=None) \n",
    "tax.columns = [\"gtdbtk_genome\", \"taxonomy\"]\n",
    "tax['ncbi_genome'] = tax['gtdbtk_genome'].str.split('_',n=1,expand=True).loc[:,1]\n",
    "gtdbtk_to_ncbi = tax.set_index('gtdbtk_genome')['ncbi_genome'].to_dict()\n",
    "ncbi_to_tax = tax.set_index('ncbi_genome')['taxonomy'].to_dict()\n",
    "tax[['Domain','Phylum','Class','Order','Family','Genus','Species']] = tax.taxonomy.apply( \n",
    "   lambda x: pd.Series(str(x).split(\";\"))) \n",
    "len(tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029 Bacteroidales genomes in GTDBTK database\n"
     ]
    }
   ],
   "source": [
    "#Select only Bacteroidales genomes\n",
    "Bt = tax[tax['taxonomy'].str.contains('Bacteroidales')]\n",
    "print(len(Bt),'Bacteroidales genomes in GTDBTK database')\n",
    "#write out taxonomy file\n",
    "Bt.to_csv(outdir+'/Bt_taxonomy.txt',index=False,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate GTDB-Tk Bacteroidales genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prodigal(genome,outdir):\n",
    "    #Annotate genomes using prodigal and identifies gyrb gene using a gtdbtk hmmprofile \n",
    "    os.system(f'gunzip ref_seqs/GTDBTK_db/fastani/database/{genome}_genomic.fna.gz')\n",
    "    os.system(f'prodigal -i ref_seqs/GTDBTK_db/fastani/database/{genome}_genomic.fna -d {outdir}/prodigal/{genome}_genomic.fna -a {outdir}/prodigal/{genome}_genomic.faa')\n",
    "    os.system(f'hmmsearch --tblout {outdir}/hmm_out/{genome}.txt ref_seqs/GTDBTK_db/markers/tigrfam/individual_hmms/TIGR01059.HMM {outdir}/prodigal/{genome}_genomic.faa')\n",
    "    os.system(f'gzip ref_seqs/GTDBTK_db/fastani/database/{genome}_genomic.fna')   \n",
    "    \n",
    "prodigal('GCF_002849695.1',outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029 genomes already annotated\n",
      "looping through remaining genomes to annotate set()\n"
     ]
    }
   ],
   "source": [
    "#Annotate genomes that haven't been annotated\n",
    "annotated_genomes = [f.split('_genomic')[0] for f in os.listdir(outdir+'/prodigal') if f.endswith('.faa')]\n",
    "\n",
    "print(len(annotated_genomes),'genomes already annotated')\n",
    "\n",
    "print('looping through remaining genomes to annotate',(set(Bt['ncbi_genome']) - set(annotated_genomes)))\n",
    "\n",
    "for genome in Bt['ncbi_genome']:\n",
    "    if os.path.exists('ref_seqs/GTDBTK_db/fastani/database/'+genome+'_genomic.fna.gz'):\n",
    "        if genome not in annotated_genomes:\n",
    "            print(genome)\n",
    "            #prodigal(genome,outdir)          \n",
    "    else:\n",
    "        print(genome,'not found in fastani folder')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify best gyrb hit and output fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCF_002849695.1', 'NZ_CP018937.1_3992', 3.499999999999998e-287]\n",
      "['GCF_000687715.1', 'NZ_JHXD01000001.1_223', 1.399999999999999e-280]\n",
      "['GCA_002353975.1', 'DEKQ01000149.1_30', 1.1999999999999993e-276]\n"
     ]
    }
   ],
   "source": [
    "def get_besthit(genome):\n",
    "    #parse hmmsearch result to return sequence header and evalue\n",
    "    try:\n",
    "        df = pd.read_csv(f'{outdir}/hmm_out/{genome}.txt')\n",
    "    except:\n",
    "        return(genome,'file_unopened','NA')\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(f'{outdir}/hmm_out/{genome}.txt',delim_whitespace=True,header=None,comment='#')\n",
    "        besthit = df.iloc[0]\n",
    "        name=besthit[0]\n",
    "        evalue=besthit[4]\n",
    "        return([genome,name,evalue])\n",
    "    except:\n",
    "        return([genome,'no_hit','NA'])\n",
    "\n",
    "\n",
    "print(get_besthit('GCF_002849695.1'))\n",
    "print(get_besthit('GCF_000687715.1')) \n",
    "print(get_besthit('GCA_002353975.1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 genomes with no hit\n",
      "0 genome files not found\n"
     ]
    }
   ],
   "source": [
    "besthits = Bt['ncbi_genome'].apply(get_besthit)\n",
    "besthits_df = pd.DataFrame(besthits.values.tolist(),columns=['genome','besthit','evalue'])\n",
    "besthits_df.to_csv(f'{outdir}/hmm_out/all_summary.txt',sep='\\t',index=None)\n",
    "print(len(besthits_df[besthits_df['besthit']=='no_hit']),'genomes with no hit')\n",
    "print(len(besthits_df[besthits_df['besthit']=='file_unopened']),'genome files not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Prevotella;s__Prevotella sp900320445\n",
      "d__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Prevotella;s__Prevotella ruminicola_B\n",
      "d__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Bacteroides;s__Bacteroides fragilis_A\n"
     ]
    }
   ],
   "source": [
    "def write_fasta(genome,besthit,evalue):\n",
    "    if besthit!='no_hit':\n",
    "        if float(evalue) < float(1e-150): \n",
    "            record_dict = SeqIO.to_dict(SeqIO.parse(f\"{outdir}/prodigal/{genome}_genomic.fna\", \"fasta\"))\n",
    "            besthit_record = record_dict[besthit]\n",
    "            besthit_record.id = genome\n",
    "            besthit_record.description=ncbi_to_tax[genome]\n",
    "            if len(besthit_record.seq) > 1800: #ensures gene is fulllength\n",
    "                if besthit_record.seq.count('N')<1:\n",
    "                    SeqIO.write(besthit_record, f\"{outdir}/gyrb_seqs/{genome}.fasta\", \"fasta\")\n",
    "                    return(ncbi_to_tax[genome])\n",
    "        else:\n",
    "            return(genome,'didnt meet cutoff')\n",
    "\n",
    "            \n",
    "print(write_fasta('GCA_900320445.1', 'ONSG01000024.1_10', '1.499999999999999e-280'))\n",
    "print(write_fasta('GCF_000687715.1', 'NZ_JHXD01000001.1_223', '1.399999999999999e-280'))\n",
    "print(write_fasta('GCF_002849695.1', 'NZ_CP018937.1_3992', '3.499999999999998e-287'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(besthits_df)):\n",
    "    try:\n",
    "        write_fasta(besthits_df.loc[i]['genome'],besthits_df.loc[i]['besthit'],besthits_df.loc[i][2])\n",
    "    except:\n",
    "        print(besthits_df.loc[i]['genome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 2.5 with Python 3.7.4\n",
      "Command line parameters: --discard-untrimmed -e .1 -g CGGAGGTAARTTCGAYAAAGG --overlap 20 -o results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta.aln.cutadapt results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta.aln\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "Finished in 0.10 s (110 us/read; 0.55 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                     892\n",
      "Reads with adapters:                       404 (45.3%)\n",
      "Reads written (passing filters):           404 (45.3%)\n",
      "\n",
      "Total basepairs processed:     2,606,424 bp\n",
      "Total written (filtered):        903,481 bp (34.7%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: CGGAGGTAARTTCGAYAAAGG; Type: regular 5'; Length: 21; Trimmed: 404 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-21 bp: 2\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "685\t137\t0.0\t2\t0 23 114\n",
      "686\t267\t0.0\t2\t45 112 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translate nucleic acid sequences\n",
      "Generate an alignment of nucleic coding regions from aligned proteins\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "#concatenate gyrb seqs to file\n",
    "mkdir -pv results/gyrb_bt_gtdbtk_ref/alignment\n",
    "cat results/gyrb_bt_gtdbtk_ref/gyrb_seqs/*.fasta > results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta\n",
    "\n",
    "#translate, align aa, and uses a guide for nucleotide seqs\n",
    "transeq -sequence results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta -outseq results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.faa\n",
    "mafft --auto --quiet results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.faa > results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.faa.aln\n",
    "tranalign -asequence  results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta -bsequence results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.faa.aln -outseq results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta.aln\n",
    "\n",
    "#run cutadapt to see where to trim alignment\n",
    "cutadapt --discard-untrimmed -e .1 -g CGGAGGTAARTTCGAYAAAGG  --overlap 20 -o results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta.aln.cutadapt results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta.aln\n",
    "rm results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb.fasta.aln.cutadapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{outdir}/alignment/gtdbtk_gyrb.fasta.aln') as original, open(f'{outdir}/alignment/gtdbtk_gyrb_amplicon.fasta', 'w') as corrected:\n",
    "    records = SeqIO.parse(original, 'fasta')\n",
    "    for record in records:\n",
    "        record.seq = record.seq[686:] #trim at position indicated by cutadapt\n",
    "        record.seq = [ch for ch in record.seq if ch != '-']\n",
    "        record.seq = ''.join(record.seq[:250])\n",
    "        record.seq = Seq.Seq(record.seq)\n",
    "        SeqIO.write(record, corrected, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translate nucleic acid sequences\n",
      "Generate an alignment of nucleic coding regions from aligned proteins\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "transeq -frame 2 -sequence results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.fasta -outseq results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.faa\n",
    "mafft --auto --quiet results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.faa > results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.faa.aln\n",
    "tranalign -asequence  results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.fasta  -bsequence results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.faa.aln -outseq results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.fasta.aln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 05/19/2020 14:14:08\n",
      "New DB name:   /Volumes/AHN/captive_ape_microbiome/results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.fasta\n",
      "New DB title:  results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /Volumes/AHN/captive_ape_microbiome/results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 892 sequences in 0.029567 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 05/19/2020 14:14:08\n",
      "New DB name:   /Volumes/AHN/captive_ape_microbiome/results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.faa\n",
      "New DB title:  results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.faa\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /Volumes/AHN/captive_ape_microbiome/results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.faa\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 892 sequences in 0.021523 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: results/gyrb_bt_gtdbtk_ref/blast_db: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir results/gyrb_bt_gtdbtk_ref/blast_db\n",
    "cp results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.fasta results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.fasta\n",
    "cp results/gyrb_bt_gtdbtk_ref/alignment/gtdbtk_gyrb_amplicon.faa results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.faa\n",
    "makeblastdb -in results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.fasta -dbtype nucl\n",
    "makeblastdb -in results/gyrb_bt_gtdbtk_ref/blast_db/gtdbtk_gyrb_amplicon.faa -dbtype prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
