{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ete3 import Tree\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_HR(sampleNames,sample_type_dict):\n",
    "    \"\"\"given a list of sample names uses sample type dictionary to determine how many sample types are present\n",
    "    designates ASVs as host restricted = 1 sample type or mixed = multiple sample types.\n",
    "    Captive sample types are not considered so some clades will have a 0 sample type length. they can fall within\n",
    "    host-restricted clades or mixed clades or neither\"\"\"\n",
    "    sampleTypes = [sample_type_dict[name] for name in sampleNames]\n",
    "    sampleTypes = [x.replace('non_industrialized_','').replace('industrialized_','') for x in sampleTypes]\n",
    "    neutral_sampleTypes = ['captive_gorilla','captive_bonobo','captive_chimp','captive_orangutan']\n",
    "    captiveNames = [name for name in sampleNames if 'captive' in sample_type_dict[name]]\n",
    "    HR_sampleTypes = list(set(sampleTypes) - set(neutral_sampleTypes))\n",
    "    HR_sampleNum = len([x for x in sampleTypes if x not in neutral_sampleTypes])\n",
    "    CP_sampleTypes = list(set(sampleTypes) & set(neutral_sampleTypes))\n",
    "    CP_sampleNum = len([x for x in sampleTypes if x in neutral_sampleTypes])\n",
    "    CP_pres = True if len(CP_sampleTypes) > 0 else False\n",
    "    if len(HR_sampleTypes) == 0:\n",
    "        HR_cat,HR_type='Unique_CP','Unique_CP'\n",
    "    if len(HR_sampleTypes) == 1: #identifies host-restricted clades\n",
    "        HR_cat,HR_type='HR','HR_'+HR_sampleTypes[0]  \n",
    "    if len(HR_sampleTypes) > 1: \n",
    "        HR_cat = 'MX'\n",
    "        if len(HR_sampleTypes) == 2:\n",
    "            if 'human' in HR_sampleTypes:\n",
    "                HR_type = 'MX_human_single_wild_ape'\n",
    "            else:\n",
    "                HR_type = 'MX_2_wild_apes'\n",
    "        if len(HR_sampleTypes) == 3:\n",
    "            if 'human' in HR_sampleTypes:\n",
    "                HR_type = 'MX_human_2_wild_apes'\n",
    "            else:\n",
    "                HR_type = 'MX_3_wild_apes'\n",
    "        if len(HR_sampleTypes) == 4:\n",
    "            HR_type = 'MX_4_hominids'\n",
    "        \n",
    "    return(HR_sampleTypes,HR_sampleNum,HR_cat,HR_type,CP_pres,CP_sampleNum,CP_sampleTypes,captiveNames)\n",
    "\n",
    "def asv_hr_table(asv_table_file,metadata_file,tax_table_file):\n",
    "    asv_table = pd.read_csv(asv_table_file,sep='\\t',index_col=0)\n",
    "    sampleNames = asv_table.apply(lambda row: list(row.index[row>0]),axis=1)\n",
    "    asv_df = sampleNames.reset_index()\n",
    "    asv_df.columns = ['ASV','sampleNames']\n",
    "    asv_df['sampleNum'] = asv_df['sampleNames'].apply(lambda names: len(names))\n",
    "    \n",
    "    #add host restriction info\n",
    "    metadata = pd.read_csv(metadata_file,sep='\\t',index_col=None)\n",
    "    sample_type_dict = dict(zip(metadata['X.SampleID'], metadata['Description'])) \n",
    "    hr = asv_df['sampleNames'].apply(lambda x: pd.Series(is_HR(x,sample_type_dict),\n",
    "                                                         index=['HR_sampleTypes','HR_sampleNum','HR_cat','HR_type',\n",
    "                                                                'CP_pres','CP_sampleNum','CP_sampleTypes','captiveNames']))\n",
    "    asv_hr_df = asv_df.merge(hr,left_index=True, right_index=True)\n",
    "    \n",
    "    #add taxonomic info\n",
    "    tax_table = pd.read_csv(tax_table_file,sep='\\t',index_col=None)\n",
    "    tax_table = tax_table[['ASV','Phylum','Order','Family','Genus']]\n",
    "    tax_table['Family'] = tax_table['Family'].fillna('unclassified') \n",
    "    tax_table['Family'] = tax_table['Family'].apply(lambda x: 'unclassified' if 'unclassified' in x else x)\n",
    "    tax_table['Genus'] = tax_table['Genus'].fillna('unclassified') \n",
    "    tax_table['Genus'] = tax_table['Genus'].apply(lambda x: 'unclassified' if 'unclassified' in x else x)\n",
    "    asv_full = asv_hr_df.merge(tax_table,on='ASV',how='left')\n",
    "    \n",
    "    return(asv_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consensus_taxonomy(listASVs,tax_fam_dict,tax_gen_dict):\n",
    "    \"\"\"Because multiple ASVs in a single clade, we determine the taxonomy of the clade by consensus.\n",
    "    If all ASVs in the clade belong to a given bacterial taxonomic family/genus the clade is assigned that taxonomy\n",
    "    If the clade contains ASVs assigned to multiple families/genera the taxonomy is labeled as unclassified.\"\"\"\n",
    "    fam = list(set([tax_fam_dict[ASV] for ASV in listASVs])-set(['unclassified']))\n",
    "    gen = list(set([tax_gen_dict[ASV] for ASV in listASVs])-set(['unclassified']))\n",
    "    fam = fam[0].split('__')[1] if len(fam) == 1 else 'unclassified'\n",
    "    if fam == 'unclassified':\n",
    "        gen='unclassified'\n",
    "    else:\n",
    "        gen = gen[0].split('__')[1] if len(gen) == 1 else 'unclassified'  \n",
    "    return(fam+'_'+gen)   \n",
    "\n",
    "def search_clades(tree, samples_cutoff, BS_support,ASV_sampleName_dict):\n",
    "    \"\"\"Finds nodes with at least 50% BS support containing ASVs only found in a single wild ape species\n",
    "    ie wild_gorilla, wild_chimp or wild_bonobo, cpat\"\"\"\n",
    "    clades_prelim = []\n",
    "    counter = 1\n",
    "    for n in tree.traverse():\n",
    "        if n.support > float(BS_support): #makes sure Bootstrap support is over threshold\n",
    "            ASVs = [leaf.name for leaf in n.iter_leaves() if 'ASV' in leaf.name]\n",
    "            listoflists = [ASV_sampleName_dict[ASV] for ASV in ASVs]\n",
    "            sampleNames = list(set(list(itertools.chain.from_iterable(listoflists))))\n",
    "            cladeName='clade_'+str(counter)\n",
    "            counter+=1\n",
    "            clade = [cladeName,ASVs,sampleNames]\n",
    "            if len(sampleNames)>samples_cutoff:\n",
    "                clades_prelim.append(clade)\n",
    "    clades_prelim = pd.DataFrame(clades_prelim, columns = \n",
    "                          ['cladeName','ASVs','sampleNames'])\n",
    "    clades_prelim['sampleNum'] = clades_prelim['sampleNames'].apply(lambda x: len(x))\n",
    "    clades_prelim['ASVsNum'] = clades_prelim['ASVs'].apply(lambda x: len(x))\n",
    "    return(clades_prelim)\n",
    "\n",
    "def eliminate_redundant_clades(clades_df,offlimits_ASVs):\n",
    "    \"\"\"sorts clades and returns the largest non overlapping clade \"\"\"\n",
    "    df = clades_df.sort_values('ASVsNum',ascending=False) #start with the largest clades first\n",
    "    NRclades = []\n",
    "    for index, row in df.iterrows():\n",
    "        if len(set(row['ASVs']) & set(offlimits_ASVs)) == 0: \n",
    "            offlimits_ASVs = offlimits_ASVs + row['ASVs']\n",
    "            NRclades.append(row['cladeName']) \n",
    "    res = df[df['cladeName'].isin(NRclades)]   \n",
    "    return(res)  \n",
    "\n",
    "def expand_clades(clades_df):\n",
    "    ASV = clades_df.apply(lambda x: pd.Series(x['ASVs']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    ASV.name = 'ASVs'\n",
    "    clades_ASVs_df = clades_df.drop('ASVs', axis=1).join(ASV)\n",
    "    return(clades_ASVs_df)\n",
    "                                 \n",
    "def host_restricted_clades(asv_table_file,metadata_file,tax_table_file,tree_file):\n",
    "    asv_table = pd.read_csv(asv_table_file,sep='\\t',index_col=0)\n",
    "    sampleNames = asv_table.apply(lambda row: list(row.index[row>0]),axis=1)\n",
    "    ASV_sampleName_dict = dict(zip(sampleNames.index,sampleNames))\n",
    "\n",
    "    #sample to sample type category\n",
    "    metadata = pd.read_csv(metadata_file,sep='\\t',index_col=None)\n",
    "    sample_type_dict = dict(zip(metadata['X.SampleID'], metadata['Description']))\n",
    "\n",
    "    #taxonomic info, family and genus\n",
    "    tax_table = pd.read_csv(tax_table_file,sep='\\t',index_col=None)\n",
    "    tax_table['Family'] = tax_table['Family'].apply(lambda x: 'unclassified' if 'unclassified' in x else x)\n",
    "    tax_table['Genus'] = tax_table['Genus'].apply(lambda x: 'unclassified' if 'unclassified' in x else x)\n",
    "    tax_fam_dict = dict(zip(tax_table['ASV'], tax_table['Family']))\n",
    "    tax_gen_dict = dict(zip(tax_table['ASV'], tax_table['Genus']))\n",
    "    \n",
    "    #search tree for clades\n",
    "    fulltree = Tree(tree_file, format=0)\n",
    "    clades_prelim = search_clades(fulltree, 5, .5, ASV_sampleName_dict)\n",
    "    hr =clades_prelim['sampleNames'].apply(lambda x:  pd.Series(is_HR(x,sample_type_dict),\n",
    "                index=['HR_sampleTypes','HR_sampleNum','HR_cat','HR_type',\n",
    "                'CP_pres','CP_sampleNum','CP_sampleTypes','captiveNames']))\n",
    "    clades_prelim_hr = clades_prelim.merge(hr,right_index=True,left_index=True)\n",
    "\n",
    "    #identify HR clades\n",
    "    HR_clades = clades_prelim_hr[clades_prelim_hr['HR_cat']=='HR']\n",
    "    HR_clades = HR_clades[HR_clades['HR_sampleNum']>=5]\n",
    "    HR_clades = eliminate_redundant_clades(HR_clades,[])\n",
    "    HR_clades_ASVs = expand_clades(HR_clades)\n",
    "\n",
    "    #identify MX clades that don't contain any HR clades\n",
    "    MX_clades = clades_prelim_hr[clades_prelim_hr['HR_cat']=='MX']\n",
    "    MX_clades = MX_clades[MX_clades['sampleNum']>=5]\n",
    "    MX_clades = eliminate_redundant_clades(MX_clades,offlimits_ASVs=list(HR_clades_ASVs['ASVs']))\n",
    "    MX_clades_ASVs = expand_clades(MX_clades)\n",
    "    \n",
    "    #identify CP clades that don't contain any HR or MX clades\n",
    "    CP_clades = clades_prelim_hr[clades_prelim_hr['HR_cat']=='Unique_CP']\n",
    "    CP_clades = CP_clades[CP_clades['sampleNum']>=5]\n",
    "    HR_MX_ASVs = list(HR_clades_ASVs['ASVs']) + list(MX_clades_ASVs['ASVs'])\n",
    "    CP_clades = eliminate_redundant_clades(CP_clades,offlimits_ASVs=HR_MX_ASVs)\n",
    "    CP_clades_ASVs = expand_clades(CP_clades)\n",
    "    \n",
    "    #merge dataframes\n",
    "    clades = pd.concat([HR_clades,MX_clades,CP_clades])\n",
    "    clades.reset_index(drop=True, inplace=True)\n",
    "    clades_ASVs = pd.concat([HR_clades_ASVs,MX_clades_ASVs,CP_clades_ASVs])\n",
    "    clades_ASVs.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    clades['cladeTax']=clades['ASVs'].apply(lambda x: \n",
    "        get_consensus_taxonomy(x,tax_fam_dict,tax_gen_dict))\n",
    "    \n",
    "    sample_type_counts =  metadata['Description'].value_counts()\n",
    "    print(sample_type_counts)\n",
    "    description_df = clades['sampleNames'].apply(lambda l: pd.Series(\n",
    "    [sample_type_dict[name] for name in l]).value_counts())\n",
    "    description_df = description_df.fillna(0)  \n",
    "    sample_type_percent = description_df/sample_type_counts\n",
    "    clades=clades.merge(sample_type_percent,left_index=True,right_index=True)  \n",
    "    \n",
    "    return(clades,clades_ASVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ete]",
   "language": "python",
   "name": "conda-env-ete-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
